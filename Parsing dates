{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1325,"sourceType":"datasetVersion","datasetId":705},{"sourceId":1360,"sourceType":"datasetVersion","datasetId":732}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [Data Cleaning](https://www.kaggle.com/learn/data-cleaning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/parsing-dates).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"In this exercise, you'll apply what you learned in the **Parsing dates** tutorial.\n\n# Setup\n\nThe questions below will give you feedback on your work. Run the following cell to set up the feedback system.","metadata":{}},{"cell_type":"code","source":"from learntools.core import binder\nbinder.bind(globals())\nfrom learntools.data_cleaning.ex3 import *\nprint(\"Setup Complete\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:32:13.643792Z","iopub.execute_input":"2026-02-06T13:32:13.644627Z","iopub.status.idle":"2026-02-06T13:32:13.649663Z","shell.execute_reply.started":"2026-02-06T13:32:13.644599Z","shell.execute_reply":"2026-02-06T13:32:13.648747Z"}},"outputs":[{"name":"stdout","text":"Setup Complete\n","output_type":"stream"}],"execution_count":70},{"cell_type":"markdown","source":"# Get our environment set up\n\nThe first thing we'll need to do is load in the libraries and dataset we'll be using. We'll be working with a dataset containing information on earthquakes that occured between 1965 and 2016.","metadata":{}},{"cell_type":"code","source":"# modules we'll use\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport datetime\n\n# read in our data\nearthquakes = pd.read_csv(\"../input/earthquake-database/database.csv\")\n\n# set seed for reproducibility\nnp.random.seed(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:32:16.983234Z","iopub.execute_input":"2026-02-06T13:32:16.984051Z","iopub.status.idle":"2026-02-06T13:32:17.082115Z","shell.execute_reply.started":"2026-02-06T13:32:16.984023Z","shell.execute_reply":"2026-02-06T13:32:17.081020Z"}},"outputs":[],"execution_count":71},{"cell_type":"markdown","source":"# 1) Check the data type of our date column\n\nYou'll be working with the \"Date\" column from the `earthquakes` dataframe.  Investigate this column now: does it look like it contains dates?  What is the dtype of the column?","metadata":{}},{"cell_type":"code","source":"# TODO: Your code here!\n# Check the first few entries\nprint(earthquakes['Date'].head())\n\n# Check the data type\nprint(earthquakes['Date'].dtype)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:32:20.497957Z","iopub.execute_input":"2026-02-06T13:32:20.499097Z","iopub.status.idle":"2026-02-06T13:32:20.505042Z","shell.execute_reply.started":"2026-02-06T13:32:20.499005Z","shell.execute_reply":"2026-02-06T13:32:20.503961Z"}},"outputs":[{"name":"stdout","text":"0    01/02/1965\n1    01/04/1965\n2    01/05/1965\n3    01/08/1965\n4    01/09/1965\nName: Date, dtype: object\nobject\n","output_type":"stream"}],"execution_count":72},{"cell_type":"markdown","source":"Once you have answered the question above, run the code cell below to get credit for your work.","metadata":{}},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq1.check()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:32:24.762068Z","iopub.execute_input":"2026-02-06T13:32:24.762626Z","iopub.status.idle":"2026-02-06T13:32:24.770217Z","shell.execute_reply.started":"2026-02-06T13:32:24.762600Z","shell.execute_reply":"2026-02-06T13:32:24.769203Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 4, \"questionId\": \"1_CheckDtype\", \"learnToolsVersion\": \"0.3.5\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct: \n\nThe \"Date\" column in the `earthquakes` DataFrame does have dates.  The dtype is \"object\".","text/markdown":"<span style=\"color:#33cc33\">Correct:</span> \n\nThe \"Date\" column in the `earthquakes` DataFrame does have dates.  The dtype is \"object\"."},"metadata":{}}],"execution_count":73},{"cell_type":"code","source":"# Line below will give you a hint\n#q1.hint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:32:27.993489Z","iopub.execute_input":"2026-02-06T13:32:27.993938Z","iopub.status.idle":"2026-02-06T13:32:27.997765Z","shell.execute_reply.started":"2026-02-06T13:32:27.993911Z","shell.execute_reply":"2026-02-06T13:32:27.996926Z"}},"outputs":[],"execution_count":74},{"cell_type":"markdown","source":"# 2) Convert our date columns to datetime\n\nMost of the entries in the \"Date\" column follow the same format: \"month/day/four-digit year\".  However, the entry at index 3378 follows a completely different pattern.  Run the code cell below to see this.","metadata":{}},{"cell_type":"code","source":"earthquakes[3378:3383]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:32:30.676850Z","iopub.execute_input":"2026-02-06T13:32:30.677133Z","iopub.status.idle":"2026-02-06T13:32:30.698235Z","shell.execute_reply.started":"2026-02-06T13:32:30.677114Z","shell.execute_reply":"2026-02-06T13:32:30.697269Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"                          Date                      Time  Latitude  Longitude  \\\n3378  1975-02-23T02:58:41.000Z  1975-02-23T02:58:41.000Z     8.017    124.075   \n3379                02/23/1975                  03:53:36   -21.727    -71.356   \n3380                02/23/1975                  07:34:11   -10.879    166.667   \n3381                02/25/1975                  05:20:05    -7.388    149.798   \n3382                02/26/1975                  04:48:55    85.047     97.969   \n\n            Type  Depth  Depth Error  Depth Seismic Stations  Magnitude  \\\n3378  Earthquake  623.0          NaN                     NaN        5.6   \n3379  Earthquake   33.0          NaN                     NaN        5.6   \n3380  Earthquake   33.0          NaN                     NaN        5.5   \n3381  Earthquake   33.0          NaN                     NaN        5.5   \n3382  Earthquake   33.0          NaN                     NaN        5.6   \n\n     Magnitude Type  ...  Magnitude Seismic Stations  Azimuthal Gap  \\\n3378             MB  ...                         NaN            NaN   \n3379             MB  ...                         NaN            NaN   \n3380             MS  ...                         NaN            NaN   \n3381             MB  ...                         NaN            NaN   \n3382             MS  ...                         NaN            NaN   \n\n      Horizontal Distance  Horizontal Error  Root Mean Square          ID  \\\n3378                  NaN               NaN               NaN  USP0000A09   \n3379                  NaN               NaN               NaN  USP0000A0A   \n3380                  NaN               NaN               NaN  USP0000A0C   \n3381                  NaN               NaN               NaN  USP0000A12   \n3382                  NaN               NaN               NaN  USP0000A1H   \n\n     Source Location Source Magnitude Source    Status  \n3378     US              US               US  Reviewed  \n3379     US              US               US  Reviewed  \n3380     US              US               US  Reviewed  \n3381     US              US               US  Reviewed  \n3382     US              US               US  Reviewed  \n\n[5 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Type</th>\n      <th>Depth</th>\n      <th>Depth Error</th>\n      <th>Depth Seismic Stations</th>\n      <th>Magnitude</th>\n      <th>Magnitude Type</th>\n      <th>...</th>\n      <th>Magnitude Seismic Stations</th>\n      <th>Azimuthal Gap</th>\n      <th>Horizontal Distance</th>\n      <th>Horizontal Error</th>\n      <th>Root Mean Square</th>\n      <th>ID</th>\n      <th>Source</th>\n      <th>Location Source</th>\n      <th>Magnitude Source</th>\n      <th>Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3378</th>\n      <td>1975-02-23T02:58:41.000Z</td>\n      <td>1975-02-23T02:58:41.000Z</td>\n      <td>8.017</td>\n      <td>124.075</td>\n      <td>Earthquake</td>\n      <td>623.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.6</td>\n      <td>MB</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>USP0000A09</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Reviewed</td>\n    </tr>\n    <tr>\n      <th>3379</th>\n      <td>02/23/1975</td>\n      <td>03:53:36</td>\n      <td>-21.727</td>\n      <td>-71.356</td>\n      <td>Earthquake</td>\n      <td>33.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.6</td>\n      <td>MB</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>USP0000A0A</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Reviewed</td>\n    </tr>\n    <tr>\n      <th>3380</th>\n      <td>02/23/1975</td>\n      <td>07:34:11</td>\n      <td>-10.879</td>\n      <td>166.667</td>\n      <td>Earthquake</td>\n      <td>33.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.5</td>\n      <td>MS</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>USP0000A0C</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Reviewed</td>\n    </tr>\n    <tr>\n      <th>3381</th>\n      <td>02/25/1975</td>\n      <td>05:20:05</td>\n      <td>-7.388</td>\n      <td>149.798</td>\n      <td>Earthquake</td>\n      <td>33.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.5</td>\n      <td>MB</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>USP0000A12</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Reviewed</td>\n    </tr>\n    <tr>\n      <th>3382</th>\n      <td>02/26/1975</td>\n      <td>04:48:55</td>\n      <td>85.047</td>\n      <td>97.969</td>\n      <td>Earthquake</td>\n      <td>33.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.6</td>\n      <td>MS</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>USP0000A1H</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Reviewed</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"},"metadata":{}}],"execution_count":75},{"cell_type":"markdown","source":"This does appear to be an issue with data entry: ideally, all entries in the column have the same format.  We can get an idea of how widespread this issue is by checking the length of each entry in the \"Date\" column.","metadata":{}},{"cell_type":"code","source":"date_lengths = earthquakes.Date.str.len()\ndate_lengths.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:32:36.866767Z","iopub.execute_input":"2026-02-06T13:32:36.867858Z","iopub.status.idle":"2026-02-06T13:32:36.882314Z","shell.execute_reply.started":"2026-02-06T13:32:36.867826Z","shell.execute_reply":"2026-02-06T13:32:36.881272Z"}},"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"Date\n10    23409\n24        3\nName: count, dtype: int64"},"metadata":{}}],"execution_count":76},{"cell_type":"markdown","source":"Looks like there are two more rows that has a date in a different format.  Run the code cell below to obtain the indices corresponding to those rows and print the data.","metadata":{}},{"cell_type":"code","source":"indices = np.where([date_lengths == 24])[1]\nprint('Indices with corrupted data:', indices)\nearthquakes.loc[indices]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:32:40.745797Z","iopub.execute_input":"2026-02-06T13:32:40.746653Z","iopub.status.idle":"2026-02-06T13:32:40.770573Z","shell.execute_reply.started":"2026-02-06T13:32:40.746625Z","shell.execute_reply":"2026-02-06T13:32:40.769752Z"}},"outputs":[{"name":"stdout","text":"Indices with corrupted data: [ 3378  7512 20650]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"                           Date                      Time  Latitude  \\\n3378   1975-02-23T02:58:41.000Z  1975-02-23T02:58:41.000Z     8.017   \n7512   1985-04-28T02:53:41.530Z  1985-04-28T02:53:41.530Z   -32.998   \n20650  2011-03-13T02:23:34.520Z  2011-03-13T02:23:34.520Z    36.344   \n\n       Longitude        Type  Depth  Depth Error  Depth Seismic Stations  \\\n3378     124.075  Earthquake  623.0          NaN                     NaN   \n7512     -71.766  Earthquake   33.0          NaN                     NaN   \n20650    142.344  Earthquake   10.1         13.9                   289.0   \n\n       Magnitude Magnitude Type  ...  Magnitude Seismic Stations  \\\n3378         5.6             MB  ...                         NaN   \n7512         5.6             MW  ...                         NaN   \n20650        5.8            MWC  ...                         NaN   \n\n       Azimuthal Gap  Horizontal Distance  Horizontal Error  Root Mean Square  \\\n3378             NaN                  NaN               NaN               NaN   \n7512             NaN                  NaN               NaN              1.30   \n20650           32.3                  NaN               NaN              1.06   \n\n               ID Source Location Source Magnitude Source    Status  \n3378   USP0000A09     US              US               US  Reviewed  \n7512   USP0002E81     US              US              HRV  Reviewed  \n20650  USP000HWQP     US              US             GCMT  Reviewed  \n\n[3 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Type</th>\n      <th>Depth</th>\n      <th>Depth Error</th>\n      <th>Depth Seismic Stations</th>\n      <th>Magnitude</th>\n      <th>Magnitude Type</th>\n      <th>...</th>\n      <th>Magnitude Seismic Stations</th>\n      <th>Azimuthal Gap</th>\n      <th>Horizontal Distance</th>\n      <th>Horizontal Error</th>\n      <th>Root Mean Square</th>\n      <th>ID</th>\n      <th>Source</th>\n      <th>Location Source</th>\n      <th>Magnitude Source</th>\n      <th>Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3378</th>\n      <td>1975-02-23T02:58:41.000Z</td>\n      <td>1975-02-23T02:58:41.000Z</td>\n      <td>8.017</td>\n      <td>124.075</td>\n      <td>Earthquake</td>\n      <td>623.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.6</td>\n      <td>MB</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>USP0000A09</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Reviewed</td>\n    </tr>\n    <tr>\n      <th>7512</th>\n      <td>1985-04-28T02:53:41.530Z</td>\n      <td>1985-04-28T02:53:41.530Z</td>\n      <td>-32.998</td>\n      <td>-71.766</td>\n      <td>Earthquake</td>\n      <td>33.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.6</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.30</td>\n      <td>USP0002E81</td>\n      <td>US</td>\n      <td>US</td>\n      <td>HRV</td>\n      <td>Reviewed</td>\n    </tr>\n    <tr>\n      <th>20650</th>\n      <td>2011-03-13T02:23:34.520Z</td>\n      <td>2011-03-13T02:23:34.520Z</td>\n      <td>36.344</td>\n      <td>142.344</td>\n      <td>Earthquake</td>\n      <td>10.1</td>\n      <td>13.9</td>\n      <td>289.0</td>\n      <td>5.8</td>\n      <td>MWC</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>32.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.06</td>\n      <td>USP000HWQP</td>\n      <td>US</td>\n      <td>US</td>\n      <td>GCMT</td>\n      <td>Reviewed</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 21 columns</p>\n</div>"},"metadata":{}}],"execution_count":77},{"cell_type":"markdown","source":"Given all of this information, it's your turn to create a new column \"date_parsed\" in the `earthquakes` dataset that has correctly parsed dates in it.  \n\n**Note**: When completing this problem, you are allowed to (but are not required to) amend the entries in the \"Date\" and \"Time\" columns.  Do not remove any rows from the dataset.","metadata":{}},{"cell_type":"code","source":"earthquakes.loc[3378, \"Date\"] = \"02/23/1975\"\nearthquakes.loc[7512, \"Date\"] = \"04/28/1985\"\nearthquakes.loc[20650, \"Date\"] = \"03/13/2011\"\nearthquakes['date_parsed'] = pd.to_datetime(earthquakes['Date'], format=\"%m/%d/%Y\")\n# Check your answer\nq2.check()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:43:36.154089Z","iopub.execute_input":"2026-02-06T13:43:36.154742Z","iopub.status.idle":"2026-02-06T13:43:36.204765Z","shell.execute_reply.started":"2026-02-06T13:43:36.154665Z","shell.execute_reply":"2026-02-06T13:43:36.203646Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"2_ConvertToDatetime\", \"learnToolsVersion\": \"0.3.5\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}],"execution_count":117},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#q2.hint()\n#q2.solution()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:32:53.362489Z","iopub.execute_input":"2026-02-06T13:32:53.363121Z","iopub.status.idle":"2026-02-06T13:32:53.367284Z","shell.execute_reply.started":"2026-02-06T13:32:53.363093Z","shell.execute_reply":"2026-02-06T13:32:53.366216Z"}},"outputs":[],"execution_count":80},{"cell_type":"markdown","source":"# 3) Select the day of the month\n\nCreate a Pandas Series `day_of_month_earthquakes` containing the day of the month from the \"date_parsed\" column.","metadata":{}},{"cell_type":"code","source":"day_of_month_earthquakes = earthquakes['date_parsed'].dt.day\n\n# Check your answer\nq3.check()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:43:03.670380Z","iopub.execute_input":"2026-02-06T13:43:03.671166Z","iopub.status.idle":"2026-02-06T13:43:03.680345Z","shell.execute_reply.started":"2026-02-06T13:43:03.671138Z","shell.execute_reply":"2026-02-06T13:43:03.679414Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 2, \"failureMessage\": \"Incorrect value for `day_of_month_earthquakes`\", \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"3_DayOfMonth\", \"learnToolsVersion\": \"0.3.5\", \"valueTowardsCompletion\": 0.0, \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Incorrect: Incorrect value for `day_of_month_earthquakes`","text/markdown":"<span style=\"color:#cc3333\">Incorrect:</span> Incorrect value for `day_of_month_earthquakes`"},"metadata":{}}],"execution_count":115},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#q3.hint()\n\n#q3.solution()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:40:18.415258Z","iopub.execute_input":"2026-02-06T13:40:18.415979Z","iopub.status.idle":"2026-02-06T13:40:18.419807Z","shell.execute_reply.started":"2026-02-06T13:40:18.415951Z","shell.execute_reply":"2026-02-06T13:40:18.418624Z"}},"outputs":[],"execution_count":105},{"cell_type":"markdown","source":"# 4) Plot the day of the month to check the date parsing\n\nPlot the days of the month from your earthquake dataset.","metadata":{}},{"cell_type":"code","source":"# TODO: Your code here\nday_of_month_earthquakes = earthquakes['date_parsed'].dt.day\nday_of_month_earthquakes = day_of_month_earthquakes.dropna()\nsns.histplot(day_of_month_earthquakes, kde=False, bins=31)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:26:43.880113Z","iopub.execute_input":"2026-02-06T13:26:43.880753Z","iopub.status.idle":"2026-02-06T13:26:44.112662Z","shell.execute_reply.started":"2026-02-06T13:26:43.880720Z","shell.execute_reply":"2026-02-06T13:26:44.111562Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Does the graph make sense to you?","metadata":{}},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq4.check()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:26:49.121403Z","iopub.execute_input":"2026-02-06T13:26:49.122005Z","iopub.status.idle":"2026-02-06T13:26:49.129643Z","shell.execute_reply.started":"2026-02-06T13:26:49.121978Z","shell.execute_reply":"2026-02-06T13:26:49.128651Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Line below will give you a hint\n#q4.hint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:26:51.810345Z","iopub.execute_input":"2026-02-06T13:26:51.810641Z","iopub.status.idle":"2026-02-06T13:26:51.814964Z","shell.execute_reply.started":"2026-02-06T13:26:51.810623Z","shell.execute_reply":"2026-02-06T13:26:51.813947Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# (Optional) Bonus Challenge\n\nFor an extra challenge, you'll work with a [Smithsonian dataset](https://www.kaggle.com/smithsonian/volcanic-eruptions) that documents Earth's volcanoes and their eruptive history over the past 10,000 years \n\nRun the next code cell to load the data.","metadata":{}},{"cell_type":"code","source":"volcanos = pd.read_csv(\"../input/volcanic-eruptions/database.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:26:55.472572Z","iopub.execute_input":"2026-02-06T13:26:55.473293Z","iopub.status.idle":"2026-02-06T13:26:55.488107Z","shell.execute_reply.started":"2026-02-06T13:26:55.473266Z","shell.execute_reply":"2026-02-06T13:26:55.487237Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Try parsing the column \"Last Known Eruption\" from the `volcanos` dataframe. This column contains a mixture of text (\"Unknown\") and years both before the common era (BCE, also known as BC) and in the common era (CE, also known as AD).","metadata":{}},{"cell_type":"code","source":"volcanos['Last Known Eruption'].sample(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T13:26:58.705051Z","iopub.execute_input":"2026-02-06T13:26:58.706030Z","iopub.status.idle":"2026-02-06T13:26:58.713125Z","shell.execute_reply.started":"2026-02-06T13:26:58.706003Z","shell.execute_reply":"2026-02-06T13:26:58.712071Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# (Optional) More practice\n\nIf you're interested in graphing time series, [check out this tutorial](https://www.kaggle.com/residentmario/time-series-plotting-optional).\n\nYou can also look into passing columns that you know have dates in them  the `parse_dates` argument in `read_csv`. (The documention [is here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html).) Do note that this method can be very slow, but depending on your needs it may sometimes be handy to use.\n\n# Keep going\n\nIn the next lesson, learn how to [**work with character encodings**](https://www.kaggle.com/alexisbcook/character-encodings).","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/data-cleaning/discussion) to chat with other learners.*","metadata":{}}]}